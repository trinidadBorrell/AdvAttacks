{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "from utils import get_coarse_arrays, eliminate_elements_torch, extract_and_normalize, generate_list, extract_values\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#with open(os.path.join(res_path, 'results.json'), 'r') as json_file:\n",
    "#    loaded_results = json.load(json_file)\n",
    "\n",
    "#with gzip.open(os.path.join(res_path, 'results.json'), 'r') as f:\n",
    "#    data2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = utils.get_imagenet_classes()\n",
    "default_weights = utils.get_default_weights()\n",
    "models_classif = utils.get_class_model_names()\n",
    "models_ = utils.get_models_ensamble(models)\n",
    "labels, index = get_coarse_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifgsm_attack(input, epsilon, data_grad, control = True, mode ='flip'):\n",
    "    iter = int(min([epsilon + 4, epsilon * 1.25]))  # Number of iterations\n",
    "\n",
    "    alpha = 1\n",
    "    pert_out = input.clone().detach()\n",
    "\n",
    "    for i in range(iter):\n",
    "        pert_out = pert_out + (alpha / 255) * data_grad.sign()\n",
    "\n",
    "        if torch.norm((pert_out - input), p=float('inf')) > epsilon / 255:\n",
    "            break\n",
    "\n",
    "    adv_pert = (pert_out - input)\n",
    "    adv_pert_max = torch.max(adv_pert)\n",
    "    adv_pert_min = torch.min(adv_pert)\n",
    "    adv_pert_plot = (adv_pert - adv_pert_min)/(adv_pert_max - adv_pert_min)\n",
    "    normalization = torch.mean(pert_out - input)\n",
    "\n",
    "    pert_out_plot = pert_out\n",
    "\n",
    "    if control == True:\n",
    "        if mode == 'flip':\n",
    "                       \n",
    "                control_pert_lr = torch.flip(adv_pert_plot, [3]) #left - right\n",
    "                control_pert_tb = torch.flip(adv_pert_plot, [2]) #top - bottom\n",
    "                transposed_image = adv_pert_plot.transpose(2, 3)\n",
    "                control_pert_diag = torch.flip(transposed_image, [2, 3]) #diagonal\n",
    "\n",
    "                mse_right_left = F.mse_loss(input, control_pert_lr).item()\n",
    "                mse_top_bottom = F.mse_loss(input, control_pert_tb).item()\n",
    "                mse_diagonal = F.mse_loss(input, control_pert_diag).item()\n",
    "\n",
    "                mse_values = {\"Top-bottom\": mse_top_bottom, \"Diagonal\": mse_diagonal, \"Right-left\": mse_right_left}\n",
    "                max_mse_flipped_type = max(mse_values, key=mse_values.get)\n",
    "                print(mse_values)\n",
    "                                \n",
    "                if max_mse_flipped_type == \"Top-bottom\":\n",
    "                    control_pert_plot = control_pert_tb\n",
    "                    control_pert = torch.flip(adv_pert, [3])\n",
    "                    print('Control: Top Bottom')\n",
    "                    control_image = control_pert + input\n",
    "\n",
    "                elif max_mse_flipped_type == \"Diagonal\":\n",
    "                    control_pert_plot = control_pert_diag\n",
    "                                        \n",
    "                    transposed_image = adv_pert.transpose(2, 3)\n",
    "                    control_pert = torch.flip(transposed_image, [2, 3])\n",
    "                    print('Control: Diagonal')\n",
    "                    control_image = control_pert + input\n",
    "\n",
    "                else:\n",
    "                    control_pert_plot = control_pert_lr\n",
    "                    control_pert = torch.flip(adv_pert, [2])\n",
    "                    print('Control: Left Right')\n",
    "                    control_image = control_pert + input\n",
    "                \n",
    "        return pert_out_plot, adv_pert_plot, control_image, control_pert_plot \n",
    "    else:\n",
    "        return pert_out_plot, adv_pert_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensamble_attack_coarse_classes_sum_full(image_folder, models, weights, epsilon, classes, targeted = False, t = '0', coarse_class = 'nada', num_classes=1000, graph=False, folder=False, sorted = True,  attack = 'iFGSM',save_path = 0, control = True, save_original = [False, 'path']):\n",
    "    \"\"\"Test function to generate adversarial images and obtain predictions using an ensemble of models.\"\"\"\n",
    "\n",
    "    save_orig, orig_save_path = save_original\n",
    "    \n",
    "    c_classes, c_index = get_coarse_arrays() \n",
    "    max_imgs = 200\n",
    "\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # Prepare output directory\n",
    "    if folder:\n",
    "        if save_path == 0:\n",
    "            if targeted == False:\n",
    "                output_dir = f\"ensamble-attack_ensamble-c_epsilon-{epsilon}-untargeted\"\n",
    "            else:\n",
    "                output_dir = f\"ensamble-attack_ensamble-c_epsilon-{epsilon}-targeted\"\n",
    "            \n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        else:\n",
    "            output_dir = save_path\n",
    "\n",
    "    results = []\n",
    "    control_res = []\n",
    "    print('Iterating over images in folder\\n\\n')\n",
    "    \n",
    "    for i, image_name in enumerate(os.listdir(image_folder)):\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        print(f'\\n\\nImage {i + 1}/{len(os.listdir(image_folder))}--------------------------------------------------------\\nImage name:{image_name}')\n",
    "\n",
    "        # Load and transform image\n",
    "        img = Image.open(image_path)\n",
    "        transformed_image = weights(img).unsqueeze(0)\n",
    "        original_image = transformed_image.clone()\n",
    "\n",
    "        # Calculate ensemble predictions\n",
    "        ensemble_outputs = []\n",
    "        transformed_image.requires_grad = True\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "\n",
    "        try:\n",
    "            output = model(normalize(transformed_image))\n",
    "            ensemble_outputs.append(output)\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            if \"output with shape [1, 1, 256, 256] doesn't match the broadcast shape [1, 3, 256, 256]\" in str(e):\n",
    "                print(\"Encountered specific RuntimeError. Moving to next element.\")\n",
    "                continue\n",
    "\n",
    "        ensemble_outputs = torch.stack(ensemble_outputs)\n",
    "        ensemble_mean_output = torch.mean(ensemble_outputs, dim=0)\n",
    "\n",
    "        # Get original predictions\n",
    "        original_output = ensemble_mean_output.clone()\n",
    "        original_probs = torch.softmax(original_output, dim=1)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        if targeted == True:\n",
    "            if type(t) == str:\n",
    "                target = original_output.max(1)[1]   #maximize original output\n",
    "                cost = -loss(original_output, target)\n",
    "            elif type(t) == int:\n",
    "                target = torch.tensor([t])           #maximize target t\n",
    "                cost = -loss(original_output, target)\n",
    "\n",
    "            elif type(t) == np.ndarray or type(t) == list:\n",
    "                w = extract_and_normalize(original_probs, t)\n",
    "                probs_t = generate_list(1000, t, w)\n",
    "                target = torch.tensor([probs_t])           \n",
    "                cost = -loss(original_output, target)\n",
    "        else:\n",
    "            if type(t) != str:\n",
    "                non_t = extract_values(np.arange(1000), t)\n",
    "                w = extract_and_normalize(original_probs, non_t)\n",
    "                probs_t = generate_list(1000, non_t, w)\n",
    "                target = torch.tensor([probs_t])           \n",
    "                cost = -loss(original_output, target)\n",
    "            else:\n",
    "                target = original_output.max(1)[1]\n",
    "                cost = loss(original_output, target)  #minimize original output\n",
    "\n",
    "        #Calculate grad\n",
    "        for model in models:\n",
    "            model.zero_grad()\n",
    "\n",
    "        #loss.backward()\n",
    "        grad = torch.autograd.grad(cost, transformed_image)[0]\n",
    "\n",
    "        # Generate adversarial image\n",
    "        if control == True:\n",
    "            perturbed_image, adv_pert, control_image, control_pert = ifgsm_attack(transformed_image, epsilon, grad, control = True)\n",
    "        else:\n",
    "            perturbed_image, adv_pert = ifgsm_attack(transformed_image, epsilon, grad, control = False)\n",
    "        # Get perturbed predictions\n",
    "        perturbed_output = torch.mean(torch.stack([model(normalize(perturbed_image)) for model in models]), dim=0)\n",
    "        perturbed_probs = torch.softmax(perturbed_output, dim=1)\n",
    "\n",
    "        if control == True:\n",
    "            control_output = torch.mean(torch.stack([model(normalize(control_image)) for model in models]), dim=0)\n",
    "            control_probs = torch.softmax(control_output, dim=1)\n",
    "\n",
    "        # Compute coarse category scores\n",
    "        #print('Fine Class --> Coarse class')\n",
    "\n",
    "        scores_original = torch.zeros(size= (len(c_index),))\n",
    "        scores_perturbed = torch.zeros(size= (len(c_index),))\n",
    "        if control == True:\n",
    "            scores_control = torch.zeros(size= (len(c_index),))\n",
    "\n",
    "        for i in np.arange(len(c_index)): #Iterate in the coarse classes\n",
    "\n",
    "            c = c_index[i] #coarse class indexs\n",
    "\n",
    "            c_values = original_probs[:, c]\n",
    "            sum = torch.sum(c_values)\n",
    "            scores_original[i] = sum\n",
    "\n",
    "            c_values_p = perturbed_probs[:, c]\n",
    "            sum_p = torch.sum(c_values_p)\n",
    "            scores_perturbed[i] = sum_p\n",
    "            \n",
    "            if control == True:\n",
    "                c_values_c = control_probs[:, c]\n",
    "                sum_c = torch.sum(c_values_c)\n",
    "                scores_control[i] = sum_c\n",
    "\n",
    "        #Eliminate values of probs (perturbed and original)\n",
    "        coarse_idx = np.hstack(c_index) #index to eliminate\n",
    "        coarse_scores = eliminate_elements_torch(original_probs[0], coarse_idx)\n",
    "        pert_coarse_scores = eliminate_elements_torch(perturbed_probs[0], coarse_idx)\n",
    "        if control == True:\n",
    "            ctrl_coarse_scores = eliminate_elements_torch(control_probs[0], coarse_idx)\n",
    "\n",
    "        new_classes = [string for idx, string in enumerate(classes) if idx not in coarse_idx]\n",
    "\n",
    "        #Concat new scores and new list of classes\n",
    "        coarse_scores = torch.cat((coarse_scores, scores_original), dim = 0)\n",
    "        pert_coarse_scores = torch.cat((pert_coarse_scores,  scores_perturbed), dim = 0)\n",
    "        if control == True:\n",
    "            ctrl_coarse_scores = torch.cat((ctrl_coarse_scores,  scores_control), dim = 0)\n",
    "\n",
    "        new_classes = new_classes + c_classes\n",
    "\n",
    "        sorted_probs_p, sorted_indices_p = torch.sort(pert_coarse_scores, descending=True)\n",
    "        sorted_classes_p = [new_classes[i] for i in sorted_indices_p]\n",
    "\n",
    "        sorted_probs, sorted_indices = torch.sort(coarse_scores, descending=True)\n",
    "        sorted_classes = [new_classes[i] for i in sorted_indices]\n",
    "\n",
    "        if folder:\n",
    "            if len(t) > 1:\n",
    "                a = targeted == True #Targeted\n",
    "                b = coarse_class != sorted_classes_p[0] #Targeted Class not equal to Top Class obtained\n",
    "\n",
    "                c = targeted == False #Not Targeted --> Original output equal to top class\n",
    "                d = coarse_class == sorted_classes_p[0] #Targeted Class not equal to Top Class obtained\n",
    "\n",
    "                e = coarse_class == sorted_classes[0] #Make sure that when I iterate over a random set of images, if I expect to have a true class T, and adv class A, these are not the same\n",
    "\n",
    "                print(f'Original top: {sorted_classes[0]}, Perturbed Top: {sorted_classes_p[0]}')\n",
    "                if  (a and b) or (c and d):\n",
    "                    print('Not verify the conditions expected')\n",
    "                    continue\n",
    "                elif e:\n",
    "                    print('Verify condition but the T (true) class is = to A (adv) class')\n",
    "                    continue\n",
    "\n",
    "        # Sort predictions\n",
    "        original_top_classes = original_probs[0].topk(num_classes)\n",
    "        perturbed_top_classes = perturbed_probs[0].topk(num_classes)\n",
    "        if control == True:\n",
    "            control_top_classes = control_probs[0].topk(num_classes)\n",
    "\n",
    "        original_dict = {classes[idx.item()]: prob.item() for idx, prob in zip(original_top_classes.indices, original_top_classes.values)}\n",
    "        perturbed_dict = {classes[idx.item()]: prob.item() for idx, prob in zip(perturbed_top_classes.indices, perturbed_top_classes.values)}\n",
    "        if control == True:\n",
    "            control_dict = {classes[idx.item()]: prob.item() for idx, prob in zip(control_top_classes.indices, control_top_classes.values)}\n",
    "\n",
    "        #sorting values \n",
    "\n",
    "        if control == True:\n",
    "            sorted_probs_c, sorted_indices_c = torch.sort(ctrl_coarse_scores, descending=True)\n",
    "            sorted_classes_c = [new_classes[i] for i in sorted_indices_c]\n",
    "\n",
    "        #define dicts with probs\n",
    "        probs_scores = {}\n",
    "        for key, value in zip(sorted_classes, sorted_probs):\n",
    "            probs_scores[key] = value.item() \n",
    "\n",
    "        probs_p_scores = {}\n",
    "        for key, value in zip(sorted_classes_p, sorted_probs_p):\n",
    "            probs_p_scores[key] = value.item() \n",
    "\n",
    "        if control == True:\n",
    "            probs_c_scores = {}\n",
    "            for key, value in zip(sorted_classes_c, sorted_probs_c):\n",
    "                probs_c_scores[key] = value.item() \n",
    "\n",
    "        results.append({'img_name': image_name, 'original': original_dict, 'perturbed': perturbed_dict, 'coarse_scores': probs_scores, 'pert_coarse_scores': probs_p_scores})\n",
    "        \n",
    "        if control == True:\n",
    "            control_res.append({'ctrl': control_dict, 'ctrl_scores': probs_c_scores})\n",
    "\n",
    "        #print(probs_c_scores)\n",
    "\n",
    "        # Save adversarial image\n",
    "        if folder:\n",
    "            counter = 1\n",
    "            \n",
    "            while True:\n",
    "                # Generate folder name\n",
    "                folder_name = f\"images_folder_{counter}_epsilon_{epsilon}\"\n",
    "                folder_path = os.path.join(output_dir, folder_name)\n",
    "\n",
    "                # Check if folder already exists\n",
    "                if not os.path.exists(folder_path):\n",
    "                    os.makedirs(folder_path)\n",
    "                    break\n",
    "                else:\n",
    "                    counter += 1\n",
    "                    if counter > max_imgs:\n",
    "                        print(f'There are {max_imgs} in the folder: MAX NUMBER REACHED.')\n",
    "                        return\n",
    "\n",
    "            perturbed_image = perturbed_image.squeeze().detach().cpu().numpy().transpose(1, 2, 0)\n",
    "            perturbed_image = np.clip(perturbed_image, 0,1)\n",
    "            perturbed_image = (perturbed_image * 255).astype('uint8')\n",
    "\n",
    "            adv_pert = adv_pert.squeeze().detach().cpu().numpy().transpose(1, 2, 0)\n",
    "            adv_pert =  np.clip(adv_pert, 0, 1)\n",
    "            adv_pert = (adv_pert * 255).astype('uint8')\n",
    "\n",
    "            if control == True:\n",
    "                control_image = control_image.squeeze().detach().cpu().numpy().transpose(1, 2, 0)\n",
    "                control_image = np.clip(control_image, 0, 1)\n",
    "                control_image = (control_image * 255).astype('uint8')\n",
    "\n",
    "                control_pert = control_pert.squeeze().detach().cpu().numpy().transpose(1, 2, 0)\n",
    "                control_pert = np.clip(control_pert, 0,1 )\n",
    "                control_pert = (control_pert * 255).astype('uint8')\n",
    "\n",
    "            atk_path = os.path.join(folder_path, 'atk.png')\n",
    "            Image.fromarray(perturbed_image).resize((720,720)).save(atk_path, optimize=True)\n",
    "            pert_path = os.path.join(folder_path, 'pert.png')\n",
    "            Image.fromarray(adv_pert).resize((720,720)).save(pert_path, optimize=True)\n",
    "\n",
    "            if control == True:\n",
    "                control_pert_path = os.path.join(folder_path, 'control_pert.png')\n",
    "                Image.fromarray(control_pert).resize((720,720)).save(control_pert_path, optimize=True)\n",
    "                control_path = os.path.join(folder_path, 'control.png')\n",
    "                Image.fromarray(control_image).resize((720,720)).save(control_path, optimize=True)\n",
    "\n",
    "            with gzip.open(os.path.join(folder_path, 'results.json.gz'), 'wt') as f:\n",
    "                json.dump(results, f)\n",
    "\n",
    "            if control == True:\n",
    "                with gzip.open(os.path.join(folder_path, 'control.json.gz'), 'wt') as f:\n",
    "                    json.dump(control, f)\n",
    "\n",
    "            if (a & b):\n",
    "                print('SAVED IMAGE. Equal Target as Top Perturbed')\n",
    "            elif (c & d):\n",
    "                print('SAVED IMAGE. Different Top Perturbed from Original')\n",
    "\n",
    "        if save_orig == True:\n",
    "            img.save(os.path.join(orig_save_path, image_name))\n",
    "\n",
    "        print(f'Epsilon: {epsilon}')\n",
    "        if targeted == True:\n",
    "            if type(t) == str:\n",
    "                print(f'Targeted Attack. Maximize Original Output\\nOriginal prob: {probs_scores[sorted_classes[0]]},\\nPerturbed prob: {probs_p_scores[sorted_classes[0]]}\\nControl prob: {probs_c_scores[sorted_classes[0]]}')\n",
    "            elif len(t) == 1:\n",
    "                print(f'Targeted Attack = {classes[t[0]]}\\nOriginal prob target: {probs_scores[classes[t[0]]]},\\nPerturbed prob target: {probs_p_scores[classes[t[0]]]}\\nControl prob target: {probs_c_scores[classes[t[0]]]}')\n",
    "            elif len(t) > 1:\n",
    "                print(f'Targeted Attack = {coarse_class}\\nOriginal prob target: {probs_scores[coarse_class]},\\nPerturbed prob target: {probs_p_scores[coarse_class]},\\nPerturbed Top class & Prob: {sorted_classes_p[0]} & {sorted_probs_p[0]}')\n",
    "                if control == True:\n",
    "                    print(f'\\nControl prob target: {probs_c_scores[coarse_class]}')\n",
    "        else:\n",
    "            print(f'Untargeted Attack. Minimize Original Output\\nOriginal prob target: {probs_scores[sorted_classes[0]]},\\nPerturbed prob target: {probs_p_scores[sorted_classes[0]]},\\nPerturbed Top class & Prob: {sorted_classes_p[0]} & {sorted_probs_p[0]}\\nControl prob target: {probs_c_scores[sorted_classes[0]]}')\n",
    "\n",
    "        if graph:\n",
    "            if folder != True:\n",
    "                perturbed_image = perturbed_image.squeeze().detach().cpu().numpy().transpose(1, 2, 0)\n",
    "                adv_pert_plot = adv_pert.squeeze().detach().cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "                if control == True:\n",
    "                    control_image = control_image.squeeze().detach().cpu().numpy().transpose(1, 2, 0)\n",
    "                    control_pert = control_pert.squeeze().detach().cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "            if control == True:\n",
    "                f, axs = plt.subplots(1, 3, figsize=(17, 5))\n",
    "                axs[0].imshow(original_image.squeeze().detach().cpu().numpy().transpose(1, 2, 0))\n",
    "                axs[0].set_title(f\"Original: {max(original_dict, key=original_dict.get)} - {np.round(max(original_dict.values()), 3)}\" + \"\\n\" + f\"Original: {max(probs_scores, key=probs_scores.get)} - {np.round(max(probs_scores.values()), 3)}\", fontsize=7)\n",
    "                axs[0].set_axis_off()\n",
    "\n",
    "                axs[1].imshow(np.clip(perturbed_image, 0, 1))\n",
    "                axs[1].set_title(f\"Perturbed: {max(perturbed_dict, key=perturbed_dict.get)} - {np.round(max(perturbed_dict.values()), 3)}\" + \"\\n\" + f\"Perturbed: {max(probs_p_scores, key=probs_p_scores.get)} - {np.round(max(probs_p_scores.values()), 3)}\", fontsize=7)\n",
    "                axs[1].set_axis_off()\n",
    "\n",
    "                axs[2].imshow(np.clip(control_image, 0, 1))\n",
    "                axs[2].set_title(f\"Control Image: {max(control_dict, key=control_dict.get)} - {np.round(max(control_dict.values()), 3)}\" + \"\\n\" + f\"Control: {max(probs_c_scores, key=probs_c_scores.get)} - {np.round(max(probs_c_scores.values()), 3)}\", fontsize=7)\n",
    "                axs[2].set_axis_off() \n",
    "\n",
    "                plt.subplots_adjust(wspace=0.5)  # Add space between the plots\n",
    "                plt.show()\n",
    "\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(adv_pert_plot)\n",
    "                plt.title(f\"Perturbation\", fontsize=7)\n",
    "                plt.axis('off') \n",
    "\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.imshow(np.clip(control_pert, 0, 1))\n",
    "                plt.title(f\"Perturbation - Control\", fontsize=7)\n",
    "                plt.axis('off') \n",
    "\n",
    "                plt.subplots_adjust(wspace=0.5)  # Add space between the plots\n",
    "                plt.show()\n",
    "            \n",
    "            else:\n",
    "                f, axs = plt.subplots(1, 3, figsize=(17, 5))\n",
    "                axs[0].imshow(original_image.squeeze().detach().cpu().numpy().transpose(1, 2, 0))\n",
    "                axs[0].set_title(f\"Original: {max(original_dict, key=original_dict.get)} - {np.round(max(original_dict.values()), 3)}\" + \"\\n\" + f\"Original: {max(probs_scores, key=probs_scores.get)} - {np.round(max(probs_scores.values()), 3)}\", fontsize=7)\n",
    "                axs[0].set_axis_off()\n",
    "\n",
    "                axs[1].imshow(np.clip(perturbed_image, 0, 1))\n",
    "                axs[1].set_title(f\"Perturbed: {max(perturbed_dict, key=perturbed_dict.get)} - {np.round(max(perturbed_dict.values()), 3)}\" + \"\\n\" + f\"Perturbed: {max(probs_p_scores, key=probs_p_scores.get)} - {np.round(max(probs_p_scores.values()), 3)}\", fontsize=7)\n",
    "                axs[1].set_axis_off()\n",
    "\n",
    "                axs[2].imshow(np.clip(adv_pert_plot, 0, 1))\n",
    "                axs[2].set_title(f\"Perturbation\", fontsize=7)\n",
    "                axs[2].set_axis_off() \n",
    "\n",
    "                plt.subplots_adjust(wspace=0.5)  # Add space between the plots\n",
    "                plt.show()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_t_cats = r'C:\\Users\\Usuario\\Documents\\Trini\\Facultad\\Tesis\\Código Personal\\Results\\Exp 3\\Target Cat\\Epsilon 2'\n",
    "save_original_success = r'C:\\Users\\Usuario\\Documents\\Trini\\Facultad\\Tesis\\Código Personal\\Results\\Exp 3\\Target Cat\\Good Images For Target'\n",
    "rndm_folders = [r'C:\\Users\\Usuario\\Documents\\Trini\\Facultad\\Tesis\\Código Personal\\image_net\\imagenet_random_images_kaggle\\imagenet\\val', r'C:\\Users\\Usuario\\Documents\\Trini\\Facultad\\Tesis\\Código Personal\\image_net\\class_images_image_net\\00151', r'C:\\Users\\Usuario\\Documents\\Trini\\Facultad\\Tesis\\Código Personal\\image_net\\class_images_image_net\\00153']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in rndm_folders:\n",
    "        test = ensamble_attack_coarse_classes_sum_full(f, models_, default_weights, 2, classes, targeted=True, t = index[0], coarse_class='cat', graph= False, folder = True, save_path=save_t_cats, save_original=[True, save_original_success], control=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
